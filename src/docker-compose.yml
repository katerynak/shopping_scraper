version: '3'
services:

  mongodb:
    container_name: mongodb
    hostname: mongodb
    image: mongo:3.0
    expose:
      - "27017"
    networks:
      - bridge
      - crawler_network
    volumes:
      - mongo-data:/data/db
    restart: always
    deploy:
      replicas: 1

  redis:
    container_name: redis
    hostname: redis
    image: redis:6.0-rc1
    expose:
      - "6379"
    networks:
      - bridge
      - crawler_network
    volumes:
      - redis-data:/data
    command: redis-server --appendonly yes
    restart: always
    deploy:
      replicas: 1

  crawler:
    hostname: crawler
    build:
      context: ./
      dockerfile: ./crawling/Dockerfile
    image: crawler
    volumes:
      - './crawling:/home/user'
      - './data_collections:/home/user/data_collections'
      - './data_processing:/home/user/data_processing'
    command: python main.py
    environment:
      - MONGODB_HOST=mongodb
      - MONGODB_PORT=27017
      - MONGODB_NAME=mydb
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - CRAWLER_PRODUCTS_INPUT_QUEUE=crawler_products_input_queue
      - CRAWLER_OUTPUT_QUEUE=crawler_output_queue
      - BROKER_PRODUCTS_OUTPUT_QUEUE=broker_products_output_queue
      - BROKER_PRODUCTS_INPUT_QUEUE=broker_products_input_queue
    networks:
      - crawler_network
#    volumes:
#      - images:/home/user/images
    depends_on:
      - broker
      - redis
      - mongodb
    restart: always
    deploy:
      replicas: 4

  client:
    hostname: client
    build:
      context: ./
      dockerfile: ./client/Dockerfile
    image: client
    volumes:
      - './client:/home/user'
      - './data_collections:/home/user/data_collections'
    ports:
      - 5000:5000
    command: python main.py
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - MONGODB_HOST=mongodb
      - MONGODB_PORT=27017
      - MONGODB_NAME=mydb
      - CRAWLER_PRODUCTS_INPUT_QUEUE=crawler_products_input_queue
      - BROKER_PRODUCTS_OUTPUT_QUEUE=broker_products_output_queue
      - BROKER_PRODUCTS_INPUT_QUEUE=broker_products_input_queue

    networks:
      - bridge
    depends_on:
      - redis
      - mongodb
      - broker
      - crawler
    restart: always
    deploy:
      replicas: 1

  broker:
    hostname: broker
    build:
      context: ./
      dockerfile: ./broker/Dockerfile
    image: broker
    volumes:
      - './broker:/home/user'
      - './data_collections:/home/user/data_collections'
      - './data_processing:/home/user/data_processing'
    command: python main.py
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - MONGODB_HOST=mongodb
      - MONGODB_PORT=27017
      - MONGODB_NAME=mydb
      - CRAWLER_PRODUCTS_INPUT_QUEUE=crawler_products_input_queue
      - CRAWLER_OUTPUT_QUEUE=crawler_output_queue
      - BROKER_PRODUCTS_OUTPUT_QUEUE=broker_products_output_queue
      - BROKER_PRODUCTS_INPUT_QUEUE=broker_products_input_queue
    networks:
      - bridge
      - crawler_network
    depends_on:
      - redis
      - mongodb
    deploy:
      replicas: 1

networks:
  bridge:
  crawler_network:

volumes:
  mongo-data:
  redis-data:
